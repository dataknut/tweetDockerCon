---
title: "#BluePlanet2: Tweet Analysis"
author: "Ben Anderson (`@dataknut`)"
date: 'Last run at: `r Sys.time()`'
output:
  html_document:
    keep_md: yes
    number_sections: yes
    self_contained: no
    toc: yes
    toc_float: yes
  pdf_document:
    number_sections: yes
    toc: yes
    toc_depth: 3
bibliography: ~/bibliography.bib
---
```{r knitrSetUp, include=FALSE}
knitr::opts_chunk$set(echo = FALSE) # do not echo code
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(fig_caption = TRUE)
knitr::opts_chunk$set(fig_height = 6) # default, make it bigger to stretch vertical axis
knitr::opts_chunk$set(fig_width = 8) # full width
knitr::opts_chunk$set(tidy = TRUE) # tidy up code in case echo = TRUE
```

```{r codeSetup, include=FALSE}
# Housekeeping ----
rm(list=ls(all=TRUE)) # remove all objects from workspace

# Set start time ----
startTime <- proc.time()

# default code location - needed to load functions & parameters correctly so 
# has to be run here and not in the functions file as we can't find the functions file without it!
# use Mikey Harper's code to work out where we are
# only problem with this is that if you print projLoc this will reveal the full path (including username) in any output document
mh_findParentDirectory <- function(Parent){
  directory <-getwd()
  while(basename(directory) != Parent){
    directory <- dirname(directory)
    
  }
return(directory)
}

projLoc <- mh_findParentDirectory("tweetR")

# Functions ----
print(paste0("Loading functions from ", projLoc,"/twitterFunctions.R"))
source(paste0(projLoc,"/twitterFunctions.R"))

# Libraries ----
# Libs for functions set in twitterFunctions.R
# additional libs required by this code
reqLibs <- c("ggplot2", "plotly", "knitr")

print(paste0("Loading the following libraries using lb_myRequiredPackages: ", reqLibs))
# Use Luke's function to require/install/load
lb_myRequiredPackages(reqLibs,"http://cran.rstudio.com/")
```

```{r set parameters}
startDay <- as.Date("2017-10-28") #BluePlanet2 pre-start
endDay <- as.Date("2017-10-31") # allow for post start excitement
hashTag <- "#BluePlanet2"
oFile <- "~/Data/twitter/BluePlanet2_tweets" # where the results are saved (do not include suffix)
timeZone <- "UTC" # important if you are not on UTC!
```


# Purpose

To extract and visualise tweets and re-tweets of `#BluePlanet2` for October-November, 2017.

Borrowing extensively from http://thinktostart.com/twitter-authentification-with-r/

We used the Twitter search API to extract 'all' tweets with the `#dockercon` hashtag. As the [Twitter search API documentation](https://dev.twitter.com/rest/public/search) (sort of) makes clear this may not be `all` such tweets but merely the `most relevant` (whatever that means) from within a `sample` (whatever that means). 

>"It allows queries against the indices of recent or popular Tweets and behaves similarly to, but not exactly like the Search feature available in Twitter mobile or web clients, such as Twitter.com search. The Twitter Search API searches against a sampling of recent Tweets published in the past 7 days." https://dev.twitter.com/rest/public/search, Accessed 12/5/2017

It is therefore possible that not quite all tweets have been extracted although it seems likely that we have captured most `human` tweeting which was our main intention. Future work should instead use the Twitter [streaming API](https://dev.twitter.com/streaming/overview).

# Load Data

You can either collect data from scratch (takes a while) or load the pre-collected data (have to remember to re-run it :-)

This produces a data table with the following variables (after some processing):

```{r load Data}
# set authentication ----
source("setTwitterAuth.R")
# collect tweets ----
maxTweets <- 50000 # let's hope that's enough - just Sunday = 48k!
#tweetListDT <- ba_collectTweets(maxTweets,startDay, endDay, hashTag, oFile)
  
# or load from pre-collected if you are getting rate limited ----
f <- paste0(oFile,"_allTweets.csv")
try(tweetListDT <- as.data.table(read_csv(f)))

# add stuff (especially dates & times) ----
tweetListDT <- ba_setUseFullTimes(tweetListDT,timeZone)


names(tweetListDT)
```

The table has `r ba_tidyNum(nrow(tweetListDT[isRetweet == "FALSE"]))` tweets (and `r ba_tidyNum(nrow(tweetListDT[isRetweet == "TRUE"]))` re-tweets) from `r ba_tidyNum(uniqueN(tweetListDT$screenName))` tweeters between `r min(tweetListDT$createdLocal)` and `r max(tweetListDT$createdLocal)` (Central European Time).

# Analysis

## Tweets and Tweeters over time

```{r setCaptionTimeSeries}
myCaption <- paste0("All (re)tweets containing #dockercon ", 
                      min(as.Date(tweetListDT$obsDateTime5m)),
                          " to ",
                          max(as.Date(tweetListDT$obsDateTime5m))
                          )
```

```{r allDaysChart, fig.height=8, fig.width=9, fig.cap=myCaption}

plotDT <- tweetListDT[, .(
                 nTweets = .N,
                 nTweeters = uniqueN(screenName)
               ), keyby = .(obsHourMin,isRetweetLab,obsDate)]

  myPlot <- ggplot(plotDT, aes(x = obsHourMin)) +
    geom_line(aes(y = nTweets, colour = "N tweets")) +
    geom_line(aes(y = nTweeters, colour = "N tweeters")) +
    facet_grid(eval(obsDate ~ isRetweetLab)) +
    theme(strip.text.y = element_text(size = 9, colour = "black", angle = 90)) +
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 0.5)) +
    scale_x_datetime(date_breaks = "2 hours", date_labels ="%H:%M") +
    theme(legend.position = "bottom") +
    theme(legend.title = element_blank()) +
    labs(caption = myCaption,
         x = "Time",
         y = "Count"
    )

myPlot

#ggplotly(myPlot)
```

Although there had been some low level tweeting about #BluePlanet2 on Saturday, it exploded on Sunday evening as you'd expect.

In the next sections we look day by day.

### B-Day -1: Saturday 28/10/2017

This plot is zoomable - try it!

```{r day-1 Chart, fig.height=8, fig.width=9, fig.cap=myCaption}
myCaption <- paste0("All (re)tweets containing #BluePlanet2 Saturday 28th October 2017")

myPlot <- ba_make5MinTimeSeriesChart(tweetListDT[obsDate == "2017-10-28"], 
                                byVars = c("obsDateTime5m,isRetweetLab"),
                                facetForm = c("isRetweetLab ~ .")
                                )

#myPlot

ggplotly(myPlot)
```

### B-Day: Sunday 29/10/2017 (First episode)

This plot is zoomable - try it!

```{r day 1 Chart, fig.height=8, fig.width=9, fig.cap=myCaption}
myCaption <- paste0("All (re)tweets containing #BluePlanet2 Sunday 29th October 2017")

myPlot <- ba_make5MinTimeSeriesChart(tweetListDT[obsDate == "2017-10-29"], 
                                byVars = c("obsDateTime5m,isRetweetLab"),
                                facetForm = c("isRetweetLab ~ .")
                                )

#myPlot

ggplotly(myPlot)
```

### B-Day +1: Monday 30/11/2017 (post-broadcast excitement)

This plot is zoomable - try it!

```{r day2Chart, fig.height=8, fig.width=9, fig.cap=myCaption}
myCaption <- paste0("All (re)tweets containing #BluePlanet2 Monday 30th October 2017")

myPlot <- ba_make5MinTimeSeriesChart(tweetListDT[obsDate == "2017-10-30"], 
                                byVars = c("obsDateTime5m,isRetweetLab"),
                                facetForm = c("isRetweetLab ~ .")
                                )


ggplotly(myPlot)
```


### B-Day +2 - Tuesday 31/11/2017 (more post-broadcast excitement)

If you see nothing, nothing happened yet :-)

This plot is zoomable - try it!

```{r day3Chart, fig.height=8, fig.width=9, fig.cap=myCaption}
myCaption <- paste0("All (re)tweets containing #BluePlanet2 Tuesday 31st October 2017")
myPlot <- ba_make5MinTimeSeriesChart(tweetListDT[obsDate == "2017-10-31"], 
                                byVars = c("obsDateTime5m,isRetweetLab"),
                                facetForm = c("isRetweetLab ~ .")
                                )


try(ggplotly(myPlot))
```


## Location (lat/long)
We wanted to make a nice map but sadly we see that most tweets have no lat/long set.

```{r latLongPlot}
plotDT <- tweetListDT[, 
                    .(
                      nTweets = .N
                    ), by = .(latitude, longitude)]
kable(cap="All logged lat/long values",
      plotDT)
```

One day we'll draw a map. 

> NB: twitteR no longer returns twitter's best guess at 'location' :-(

## Screen name

Next we'll try by screen name.

Here's a really bad visualisation of all tweeters tweeting over time. Each row of pixels is a tweeter (the names are illegible) and a green dot indicates a few tweets in the 5 minute period while a red dot indicates a lot of tweets.

```{r screenNameAll, fig.height=8,fig.cap="N tweets per 5 minutes by screen name"}
myCaption <- paste0("All (re)tweets containing #dockercon ", 
                      min(as.Date(tweetListDT$obsDateTime5m)),
                          " to ",
                          max(as.Date(tweetListDT$obsDateTime5m))
                          )

plotDT <- tweetListDT[, 
                    .(
                      nTweets = .N
                    ), by = .(screenName, obsDateTime5m)]

myPlot <- ggplot(plotDT, aes(x = obsDateTime5m)) +
    geom_tile(aes(y = screenName, fill = nTweets)) +
    theme(strip.text.y = element_text(size = 9, colour = "black", angle = 0)) +
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 0.5)) +
    #scale_x_reverse() + # fix reverse plotting of long
    scale_x_datetime(date_breaks = "4 hours", date_labels ="%d %b %H:%M") +
    scale_fill_gradient(low="green", high = "red") +
    theme(legend.position = "bottom") +
    theme(legend.title = element_blank()) +
    labs(caption = myCaption,
         x = "Time",
         y = "Screen name"
    )

myPlot
```

Yeah, that worked well.

So let's re-do that for the top 50 tweeters so we can see their tweetStreaks...

Top tweeters:

```{r topTweeters}
allTweetersDT <- tweetListDT[, .(nTweets = .N), by = screenName][order(-nTweets)]

kable(caption = "Top 15 tweeters (all days)",
      head(allTweetersDT, 15)
      )
```

And their tweetStreaks...

```{r screenNameTop50, fig.height=8,fig.cap="N tweets per 5 minutes by screen name (top 50, reverse alphabetical)"}
myCaption <- paste0("All (re)tweets containing #dockercon ", 
                      min(as.Date(tweetListDT$obsDateTime5m)),
                          " to ",
                          max(as.Date(tweetListDT$obsDateTime5m)),
                    "\nReverse alphabetical"
                          )

matchDT <- head(allTweetersDT,50)
matchDT <- matchDT[, maxT := nTweets]
setkey(matchDT, screenName)
setkey(tweetListDT, screenName)

tempDT <- merge(tweetListDT, matchDT)

plotDT <- tempDT[matchDT, 
                    .(
                      nTweets = .N
                    ), keyby = .(maxT,screenName, obsDateTime5m)]

plotDT <- plotDT[order(plotDT$screenName,plotDT$maxT)]

myPlot <- ggplot(plotDT, aes(x = obsDateTime5m)) +
    geom_tile(aes(y = screenName, fill = nTweets)) +
    theme(strip.text.y = element_text(size = 9, colour = "black", angle = 0)) +
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 0.5)) +
    #scale_x_reverse() + # fix reverse plotting of long
    scale_x_datetime(date_breaks = "4 hours", date_labels ="%d %b %H:%M") +
    scale_fill_gradient(low="green", high = "red") +
    theme(legend.position = "bottom") +
    theme(legend.title = element_blank()) +
    labs(caption = myCaption,
         x = "Time",
         y = "Screen name"
    )

#ggplotly(myPlot)

myPlot 
```

Spot the twitterBots...

# About

```{r check runtime}
t <- proc.time() - startTime

elapsed <- t[[3]]
```

Analysis completed in `r elapsed` seconds ( `r round(elapsed/60,2)` minutes) using [knitr](https://cran.r-project.org/package=knitr) in [RStudio](http://www.rstudio.com) with `r R.version.string` running on `r R.version$platform`.

A special mention must go to `twitteR` [@twitteR] for the twitter API interaction functions and `lubridate` [@lubridate] which allows timezone manipulation without too many tears.

Other R packages used:

 * base R - for the basics [@baseR]
 * data.table - for fast (big) data handling [@data.table]
 * readr - for nice data loading [@readr]
 * ggplot2 - for slick graphs [@ggplot2]
 * plotly - fancy, zoomable slick graphs [@plotly]
 * twitteR - twitter API search [@twitteR]
 * knitr - to create this document [@knitr]

# References


